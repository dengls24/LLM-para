import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

def compute_and_plot_transformer_analysis(
    hidden_size: int,
    num_heads: int,
    seq_len: int,
    batch_size: int,
    num_layers: int,
    quant_config: dict,
    intermediate_size: int = None,  # æ–°å¢å‚æ•°
    num_key_value_heads: int = None,  # æ–°å¢GQAå‚æ•°
    out_l: int = 0,
    max_gen_len: int = 4096,  # æ–°å¢å‚æ•°ï¼Œæœ€å¤§ç”Ÿæˆé•¿åº¦
    output_csv_path: str = "true_density_transformer_analysis.csv",
    use_gate_ffn: bool = False,  # æ–°å¢å‚æ•°ï¼Œæ˜¯å¦ä½¿ç”¨gateæœºåˆ¶çš„FFN
    use_rope: bool = True,  # æ–°å¢å‚æ•°ï¼Œæ˜¯å¦ä½¿ç”¨RoPE
    rope_theta: float = 10000.0,  # æ–°å¢å‚æ•°ï¼ŒRoPEçš„thetaå‚æ•°
    rope_scaling_factor: float = 1.0  # æ–°å¢å‚æ•°ï¼ŒRoPEçš„ç¼©æ”¾å› å­ï¼Œç”¨äºé•¿åº¦å¤–æ¨
):
    d = hidden_size // num_heads
    b, s, h, n, L = batch_size, seq_len, hidden_size, num_heads, num_layers
    o_l = out_l
    # å¦‚æœæœªæŒ‡å®šintermediate_sizeï¼Œåˆ™é»˜è®¤ä½¿ç”¨4*h
    if intermediate_size is None:
        intermediate_size = 4 * h
    
    # å¦‚æœæœªæŒ‡å®šnum_key_value_headsï¼Œåˆ™é»˜è®¤ç­‰äºnum_headsï¼ˆæ ‡å‡†æ³¨æ„åŠ›ï¼‰
    if num_key_value_heads is None:
        num_key_value_heads = num_heads
    
    # KVå¤´æ•°
    kv_n = num_key_value_heads
    
    def byte_size(shape, bitwidth):
        num_elements = 1
        for dim in shape:
            num_elements *= dim
        return num_elements * bitwidth / 8

    data = []

    def add_row(phase, name, input1, input2, output,
                flops, param_count,
                input_shape, weight_shape, output_shape,
                act_bits, weight_bits, note=""):

        B_input = byte_size(input_shape, act_bits)
        B_output = byte_size(output_shape, act_bits)
        B_weight = byte_size(weight_shape, weight_bits) if weight_shape else 0

        B_total = B_input + B_output + B_weight
        density = "-" if B_total == 0 else round(flops / B_total, 2)

        data.append({
            "Phase": phase,
            "Operation": name,
            "FLOPs": flops,
            "Param Count": param_count,
            "Input1 Bytes": B_input,
            "Input2 Bytes": B_weight,
            "Output Bytes": B_output,
            "Total Bytes": B_total,
            "Density (Op/Byte)": density
        })

    # Quant settings
    a_bit = quant_config["activation"]
    w_attn = quant_config["weight_attn"]
    w_ffn = quant_config["weight_ffn"]
    kv_bit = quant_config["kv_cache"]
    rope_bit = quant_config["rope_bit"]

    # === PREFILL PHASE ===
    phase = "Prefill"
    seq = s

    # å¯¹äºW_Qï¼Œä½¿ç”¨å®Œæ•´çš„num_heads
    flops = 2 * b * seq * h * h
    param_count = h * h
    add_row(phase, "xW_Q", "(b,s,h)", "(h,h)", "(b,s,h)",
            flops, param_count, (b, seq, h), (h, h), (b, seq, h), a_bit, w_attn)
    
    # å¯¹äºW_Kå’ŒW_Vï¼Œä½¿ç”¨num_key_value_heads
    for name in ['W_K', 'W_V']:
        # å¯¹äºGQAï¼ŒKå’ŒVçš„å‚æ•°é‡å’Œè®¡ç®—é‡ä¼šå‡å°‘
        flops = 2 * b * seq * h * h * (kv_n / n)
        param_count = h * h * (kv_n / n)
        add_row(phase, f"x{name}", "(b,s,h)", f"(h,h*{kv_n/n})", "(b,s,h)",
                flops, param_count, (b, seq, h), (h, h * (kv_n / n)), (b, seq, h), a_bit, w_attn)
    
    # æ·»åŠ RoPEè®¡ç®—
    if use_rope:
        # RoPEåº”ç”¨äºQå’ŒKï¼Œè®¡ç®—æ¯ä¸ªå¤´çš„æ—‹è½¬æ“ä½œ
        # æ¯ä¸ªä½ç½®éœ€è¦è®¡ç®—sinå’Œcosï¼Œç„¶ååº”ç”¨æ—‹è½¬å˜æ¢
        # å¯¹äºæ¯ä¸ªä½ç½®å’Œæ¯ä¸ªå¤´çš„æ¯ä¸ªç»´åº¦å¯¹(dim_i, dim_i+1)ï¼Œéœ€è¦4ä¸ªFLOPs(2æ¬¡ä¹˜æ³•ï¼Œ2æ¬¡åŠ æ³•)
        # æ€»å…±æœ‰seqä¸ªä½ç½®ï¼Œnä¸ªQå¤´ï¼Œkv_nä¸ªKå¤´ï¼Œd/2ä¸ªç»´åº¦å¯¹
        
        # Qçš„RoPEè®¡ç®—
        rope_q_flops = b * seq * n * (d // 2) * 4  # 4 = 2æ¬¡ä¹˜æ³• + 2æ¬¡åŠ æ³•
        add_row(phase, "RoPE-Q", "(b,n,s,d)", "(s,d)", "(b,n,s,d)",
                rope_q_flops, 0, (b, n, seq, d), (seq, d), (b, n, seq, d), a_bit, rope_bit,
                note=f"RoPE theta={rope_theta}, scaling={rope_scaling_factor}")
        
        # Kçš„RoPEè®¡ç®—
        rope_k_flops = b * seq * kv_n * (d // 2) * 4  # 4 = 2æ¬¡ä¹˜æ³• + 2æ¬¡åŠ æ³•
        add_row(phase, "RoPE-K", "(b,kv_n,s,d)", "(s,d)", "(b,kv_n,s,d)",
                rope_k_flops, 0, (b, kv_n, seq, d), (seq, d), (b, kv_n, seq, d), a_bit, rope_bit,
                note=f"RoPE theta={rope_theta}, scaling={rope_scaling_factor}")

    # æ³¨æ„åŠ›è®¡ç®— - è€ƒè™‘GQA
    add_row(phase, "Q Ã— Káµ€", "(b,n,s,d)", "(b,kv_n,d,s)", "(b,n,s,s)",
            2 * b * n * seq * seq * d, 0,
            (b, n, seq, d), (b,kv_n, seq, d), (b, n, seq, seq), a_bit, kv_bit,
            note=f"GQA: {n} Q heads, {kv_n} KV heads")

    add_row(phase, "Attn Ã— V", "(b,n,s,s)", "(b,kv_n,s,d)", "(b,n,s,d)",
            2 * b * n * seq * seq * d, 0,
            (b, n, seq, seq), (b, kv_n, seq, d), (b, n, seq, d), a_bit, kv_bit,
            note=f"GQA: {n} Q heads, {kv_n} KV heads")

    add_row(phase, "xW_O", "(b,s,h)", "(h,h)", "(b,s,h)",
            2 * b * seq * h * h, h * h,
            (b, seq, h), (h, h), (b, seq, h), a_bit, w_attn)

    # ä¿®æ”¹FFN-1ï¼Œä½¿ç”¨intermediate_sizeæ›¿ä»£4*h
    # ä¿®æ”¹FFN-1ï¼Œè€ƒè™‘gateæœºåˆ¶
    if use_gate_ffn:
        # è®¡ç®—Wâ‚å’ŒW_gateä¸¤ä¸ªçŸ©é˜µçš„FLOPs
        gate_flops = 2 * b * seq * h * intermediate_size * 2  # ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•
        # é¢å¤–çš„é€å…ƒç´ ä¹˜æ³•
        gate_flops += b * seq * intermediate_size  # SiLU(Wâ‚x) âŠ™ (W_gate*x)
        gate_param_count = h * intermediate_size * 2  # ä¸¤ä¸ªæƒé‡çŸ©é˜µ
        
        add_row(phase, "FFN-1 (with Gate)", "(b,s,h)", f"(h,{intermediate_size}*2)", f"(b,s,{intermediate_size})",
                gate_flops, gate_param_count, 
                (b, seq, h), (h, intermediate_size * 2), (b, seq, intermediate_size), a_bit, w_ffn,
                note="åŒ…å«Gateæœºåˆ¶")
    else:
        # åŸå§‹FFN-1è®¡ç®—
        add_row(phase, "FFN-1", "(b,s,h)", f"(h,{intermediate_size})", f"(b,s,{intermediate_size})",
                2 * b * seq * h * intermediate_size, h * intermediate_size,
                (b, seq, h), (h, intermediate_size), (b, seq, intermediate_size), a_bit, w_ffn)

    # ä¿®æ”¹FFN-2ï¼Œä½¿ç”¨intermediate_sizeæ›¿ä»£4*h
    add_row(phase, "FFN-2", f"(b,s,{intermediate_size})", f"({intermediate_size},h)", "(b,s,h)",
            2 * b * seq * h * intermediate_size, intermediate_size * h,
            (b, seq, intermediate_size), (intermediate_size, h), (b, seq, h), a_bit, w_ffn)

    # === DECODE PHASE ===
    phase = "Decode"
    seq = 1 #ç”Ÿæˆä¸€ä¸ªtoken
    hist = s
    #print (hist)
    o_l = 0  # åˆå§‹ç”Ÿæˆtokenä½ç½®
    # è®¡ç®—ç¬¬ä¸€ä¸ªtokençš„decodeé˜¶æ®µ
    # å¯¹äºW_Qï¼Œä½¿ç”¨å®Œæ•´çš„num_heads
    flops = 2 * b * seq * h * h
    param_count = h * h
    add_row(phase, "xW_Q", "(b,1,h)", "(h,h)", "(b,1,h)",
            flops, param_count, (b, seq, h), (h, h), (b, seq, h), a_bit, w_attn)
    
    # å¯¹äºW_Kå’ŒW_Vï¼Œä½¿ç”¨num_key_value_heads
    for name in ['W_K', 'W_V']:
        # å¯¹äºGQAï¼ŒKå’ŒVçš„å‚æ•°é‡å’Œè®¡ç®—é‡ä¼šå‡å°‘
        flops = 2 * b * seq * h * h * (kv_n / n)
        param_count = h * h * (kv_n / n)
        add_row(phase, f"x{name}", "(b,1,h)", f"(h,h*{kv_n/n})", "(b,1,h)",
                flops, param_count, (b, seq, h), (h, h * (kv_n / n)), (b, seq, h), a_bit, w_attn)
    
    # æ·»åŠ RoPEè®¡ç®— - Decodeé˜¶æ®µ
    if use_rope:
        # Qçš„RoPEè®¡ç®— - åªæœ‰ä¸€ä¸ªtoken
        rope_q_flops = b * 1 * n * (d // 2) * 4  # 4 = 2æ¬¡ä¹˜æ³• + 2æ¬¡åŠ æ³•
        add_row(phase, "RoPE-Q", "(b,n,1,d)", "(1,d)", "(b,n,1,d)",
                rope_q_flops, 0, (b, n, 1, d), (1, d), (b, n, 1, d), a_bit, rope_bit,
                note=f"RoPE theta={rope_theta}, scaling={rope_scaling_factor}, ä½ç½®={s+o_l}")
        
        # Kçš„RoPEè®¡ç®— - åªæœ‰ä¸€ä¸ªtoken
        rope_k_flops = b * 1 * kv_n * (d // 2) * 4  # 4 = 2æ¬¡ä¹˜æ³• + 2æ¬¡åŠ æ³•
        add_row(phase, "RoPE-K", "(b,kv_n,1,d)", "(1,d)", "(b,kv_n,1,d)",
                rope_k_flops, 0, (b, kv_n, 1, d), (1, d), (b, kv_n, 1, d), a_bit, rope_bit,
                note=f"RoPE theta={rope_theta}, scaling={rope_scaling_factor}, ä½ç½®={s+o_l}")

    # æ³¨æ„åŠ›è®¡ç®— - è€ƒè™‘GQAå’Œæ›´é•¿çš„å†å²
    add_row(phase, "Q Ã— Káµ€", "(b,n,1,d)", "(b,kv_n,d,s+o_l+1)", "(b,n,1,s+o_l+1)",
            2 * b * n * hist * d, 0,
            (b, n, 1, d), (b, kv_n, d, hist + 1), (b, n, 1, hist + 1), a_bit, kv_bit,
            note=f"GQA: {n} Q heads, {kv_n} KV heads, å†å²é•¿åº¦: {hist}")

    add_row(phase, "Attn Ã— V", "(b,n,1,s+o_l+1)", "(b,kv_n,s+o_l+1,d)", "(b,n,1,d)",
            2 * b * n * (hist + 1) * d, 0,
            (b, n, 1, hist + 1), (b, kv_n, hist + 1, d), (b, n, 1, d), a_bit, kv_bit,
            note=f"GQA: {n} Q heads, {kv_n} KV heads, å†å²é•¿åº¦: {hist}")

    add_row(phase, "xW_O", "(b,1,h)", "(h,h)", "(b,1,h)",
            2 * b * seq * h * h, h * h,
            (b, seq, h), (h, h), (b, seq, h), a_bit, w_attn)
    
    # ä¿®æ”¹FFN-1ï¼Œä½¿ç”¨intermediate_sizeæ›¿ä»£4*h
    # ä¿®æ”¹FFN-1ï¼Œè€ƒè™‘gateæœºåˆ¶
    if use_gate_ffn:
        # è®¡ç®—Wâ‚å’ŒW_gateä¸¤ä¸ªçŸ©é˜µçš„FLOPs
        gate_flops = 2 * b * seq * h * intermediate_size * 2  # ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•
        # é¢å¤–çš„é€å…ƒç´ ä¹˜æ³•
        gate_flops += b * seq * intermediate_size  # SiLU(Wâ‚x) âŠ™ (W_gate*x)
        gate_param_count = h * intermediate_size * 2  # ä¸¤ä¸ªæƒé‡çŸ©é˜µ
        
        add_row(phase, "FFN-1 (with Gate)", "(b,s,h)", f"(h,{intermediate_size}*2)", f"(b,s,{intermediate_size})",
                gate_flops, gate_param_count, 
                (b, seq, h), (h, intermediate_size * 2), (b, seq, intermediate_size), a_bit, w_ffn,
                note="åŒ…å«Gateæœºåˆ¶")
    else:
        # åŸå§‹FFN-1è®¡ç®—
        add_row(phase, "FFN-1", "(b,s,h)", f"(h,{intermediate_size})", f"(b,s,{intermediate_size})",
                2 * b * seq * h * intermediate_size, h * intermediate_size,
                (b, seq, h), (h, intermediate_size), (b, seq, intermediate_size), a_bit, w_ffn)

    # ä¿®æ”¹FFN-2ï¼Œä½¿ç”¨intermediate_sizeæ›¿ä»£4*h
    add_row(phase, "FFN-2", f"(b,1,{intermediate_size})", f"({intermediate_size},h)", "(b,1,h)",
            2 * b * seq * h * intermediate_size, intermediate_size * h,
            (b, seq, intermediate_size), (intermediate_size, h), (b, seq, h), a_bit, w_ffn)

    # è®¡ç®—æœ€åä¸€ä¸ªtokençš„decodeé˜¶æ®µ
    phase = "Decode_Last"
    o_l = max_gen_len - 1  # æœ€åä¸€ä¸ªç”Ÿæˆtokençš„ä½ç½®
    hist = s + o_l  # å†å²é•¿åº¦ = åŸå§‹åºåˆ— + å·²ç”Ÿæˆçš„tokens
    
    # å¯¹äºW_Qï¼Œä½¿ç”¨å®Œæ•´çš„num_heads
    flops = 2 * b * seq * h * h
    param_count = h * h
    add_row(phase, "xW_Q", "(b,1,h)", "(h,h)", "(b,1,h)",
            flops, param_count, (b, seq, h), (h, h), (b, seq, h), a_bit, w_attn)
    
    # å¯¹äºW_Kå’ŒW_Vï¼Œä½¿ç”¨num_key_value_heads
    for name in ['W_K', 'W_V']:
        # å¯¹äºGQAï¼ŒKå’ŒVçš„å‚æ•°é‡å’Œè®¡ç®—é‡ä¼šå‡å°‘
        flops = 2 * b * seq * h * h * (kv_n / n)
        param_count = h * h * (kv_n / n)
        add_row(phase, f"x{name}", "(b,1,h)", f"(h,h*{kv_n/n})", "(b,1,h)",
                flops, param_count, (b, seq, h), (h, h * (kv_n / n)), (b, seq, h), a_bit, w_attn)
    
    # æ·»åŠ RoPEè®¡ç®— - Decode_Lasté˜¶æ®µ
    if use_rope:
        # Qçš„RoPEè®¡ç®— - åªæœ‰ä¸€ä¸ªtokenï¼Œä½†ä½ç½®æ˜¯æœ€åä¸€ä¸ª
        rope_q_flops = b * 1 * n * (d // 2) * 4  # 4 = 2æ¬¡ä¹˜æ³• + 2æ¬¡åŠ æ³•
        add_row(phase, "RoPE-Q", "(b,n,1,d)", "(1,d)", "(b,n,1,d)",
                rope_q_flops, 0, (b, n, 1, d), (1, d), (b, n, 1, d), a_bit, rope_bit,
                note=f"RoPE theta={rope_theta}, scaling={rope_scaling_factor}, ä½ç½®={s+o_l}")
        
        # Kçš„RoPEè®¡ç®— - åªæœ‰ä¸€ä¸ªtokenï¼Œä½†ä½ç½®æ˜¯æœ€åä¸€ä¸ª
        rope_k_flops = b * 1 * kv_n * (d // 2) * 4  # 4 = 2æ¬¡ä¹˜æ³• + 2æ¬¡åŠ æ³•
        add_row(phase, "RoPE-K", "(b,kv_n,1,d)", "(1,d)", "(b,kv_n,1,d)",
                rope_k_flops, 0, (b, kv_n, 1, d), (1, d), (b, kv_n, 1, d), a_bit, rope_bit,
                note=f"RoPE theta={rope_theta}, scaling={rope_scaling_factor}, ä½ç½®={s+o_l}")

    # æ³¨æ„åŠ›è®¡ç®— - è€ƒè™‘GQAå’Œæ›´é•¿çš„å†å²
    add_row(phase, "Q Ã— Káµ€", "(b,n,1,d)", "(b,kv_n,d,s+o_l+1)", "(b,n,1,s+o_l+1)",
            2 * b * n * hist * d, 0,
            (b, n, 1, d), (b, kv_n, d, hist + 1), (b, n, 1, hist + 1), a_bit, kv_bit,
            note=f"GQA: {n} Q heads, {kv_n} KV heads, å†å²é•¿åº¦: {hist}")

    add_row(phase, "Attn Ã— V", "(b,n,1,s+o_l+1)", "(b,kv_n,s+o_l+1,d)", "(b,n,1,d)",
            2 * b * n * (hist + 1) * d, 0,
            (b, n, 1, hist + 1), (b, kv_n, hist + 1, d), (b, n, 1, d), a_bit, kv_bit,
            note=f"GQA: {n} Q heads, {kv_n} KV heads, å†å²é•¿åº¦: {hist}")

    add_row(phase, "xW_O", "(b,1,h)", "(h,h)", "(b,1,h)",
            2 * b * seq * h * h, h * h,
            (b, seq, h), (h, h), (b, seq, h), a_bit, w_attn)

    # ä¿®æ”¹FFN-1ï¼Œä½¿ç”¨intermediate_sizeæ›¿ä»£4*h
    # ä¿®æ”¹FFN-1ï¼Œè€ƒè™‘gateæœºåˆ¶
    if use_gate_ffn:
        # è®¡ç®—Wâ‚å’ŒW_gateä¸¤ä¸ªçŸ©é˜µçš„FLOPs
        gate_flops = 2 * b * seq * h * intermediate_size * 2  # ä¸¤ä¸ªçŸ©é˜µä¹˜æ³•
        # é¢å¤–çš„é€å…ƒç´ ä¹˜æ³•
        gate_flops += b * seq * intermediate_size  # SiLU(Wâ‚x) âŠ™ (W_gate*x)
        gate_param_count = h * intermediate_size * 2  # ä¸¤ä¸ªæƒé‡çŸ©é˜µ
        
        add_row(phase, "FFN-1 (with Gate)", "(b,s,h)", f"(h,{intermediate_size}*2)", f"(b,s,{intermediate_size})",
                gate_flops, gate_param_count, 
                (b, seq, h), (h, intermediate_size * 2), (b, seq, intermediate_size), a_bit, w_ffn,
                note="åŒ…å«Gateæœºåˆ¶")
    else:
        # åŸå§‹FFN-1è®¡ç®—
        add_row(phase, "FFN-1", "(b,s,h)", f"(h,{intermediate_size})", f"(b,s,{intermediate_size})",
                2 * b * seq * h * intermediate_size, h * intermediate_size,
                (b, seq, h), (h, intermediate_size), (b, seq, intermediate_size), a_bit, w_ffn)

    # ä¿®æ”¹FFN-2ï¼Œä½¿ç”¨intermediate_sizeæ›¿ä»£4*h
    add_row(phase, "FFN-2", f"(b,1,{intermediate_size})", f"({intermediate_size},h)", "(b,1,h)",
            2 * b * seq * h * intermediate_size, intermediate_size * h,
            (b, seq, intermediate_size), (intermediate_size, h), (b, seq, h), a_bit, w_ffn)

    df = pd.DataFrame(data)

    df.to_csv(output_csv_path, index=False)
    # === Summary ===

    df['FLOPs'] = df['FLOPs'] * L
    df['Total Bytes'] = df['Total Bytes'] * L

    # åªè®¡ç®—prefillé˜¶æ®µçš„å‚æ•°é‡ï¼Œå¹¶æŒ‰ç…§æƒé‡ä½å®½è½¬æ¢ä¸ºGBå•ä½
    prefill_df = df[df['Phase'] == 'Prefill']
    total_params = prefill_df['Param Count'].sum() * L
    # å°†å‚æ•°é‡è½¬æ¢ä¸ºGBï¼Œè€ƒè™‘æƒé‡ä½å®½
    total_params_gb = (total_params * w_ffn / 8) / (1024**3)  # ä½¿ç”¨FFNæƒé‡ä½å®½è¿›è¡Œè½¬æ¢

    total_flops = df['FLOPs'].sum()
    total_bytes = df['Total Bytes'].sum()

    print(f"\nğŸ”¢ Total {L}-Layer Summary:")
    print(f"  FLOPs        = {total_flops:.2e} Op")
    print(f"  Param Count  = {total_params:.2e} ({total_params_gb:.2f} GB @{w_ffn}bit)")
    print(f"  Memory Access= {total_bytes / (1024**2):.2f} MB")

    # === KV Cache Write Analysis ===
    # ä¿®æ”¹KVç¼“å­˜è®¡ç®—ï¼Œè€ƒè™‘GQA
    kv_cache_bytes_per_token = L * kv_n * d * 2 * (kv_bit / 8)  # Key + Valueï¼Œåªè€ƒè™‘kv_nä¸ªå¤´
    kv_cache_total = kv_cache_bytes_per_token * s * b  # åŸå§‹åºåˆ—çš„KVç¼“å­˜

    # è®¡ç®—ç”Ÿæˆè¿‡ç¨‹ä¸­çš„KVç¼“å­˜
    gen_kv_cache_total = kv_cache_bytes_per_token * max_gen_len * b  # ç”Ÿæˆtokensçš„KVç¼“å­˜
    max_kv_cache = kv_cache_bytes_per_token * (s + max_gen_len) * b  # æœ€å¤§KVç¼“å­˜ï¼ˆåŸå§‹+ç”Ÿæˆï¼‰
    
    print(f"\nğŸ’¾ KV Cache Analysis:")
    print(f"  Per token: {kv_cache_bytes_per_token:.1f} Bytes")
    print(f"  Prefill seq: {kv_cache_total / (1024 ** 2):.2f} MB")
    print(f"  Generation: {gen_kv_cache_total / (1024 ** 2):.2f} MB")
    print(f"  Max total: {max_kv_cache / (1024 ** 2):.2f} MB (åºåˆ—é•¿åº¦: {s + max_gen_len})")
    print(f"  GQA ratio: {kv_n}/{n} = {kv_n/n:.2f}x reduction")


#     print(f"\nğŸ’¾ KV Cache Total Write:")
#     print(f"  Per token: {kv_cache_bytes_per_token:.1f} Bytes")
#     print(f"  Full seq : {kv_cache_total / (1024 ** 2):.2f} MB")
#     print(f"  GQA ratio: {kv_n}/{n} = {kv_n/n:.2f}x reduction")
    
    # è®¡ç®—ç”Ÿæˆæœ€åä¸€ä¸ªtokençš„è®¡ç®—é‡
    last_token_df = df[df['Phase'] == 'Decode_Last']
    last_token_flops = last_token_df['FLOPs'].sum() * L
    last_token_bytes = last_token_df['Total Bytes'].sum() * L
    print(f"\nğŸ”¢ ç”Ÿæˆæœ€åä¸€ä¸ªToken (ä½ç½® {max_gen_len}):")
    print(f"  FLOPs        = {last_token_flops:.2e} Op")
    print(f"  Memory Access= {last_token_bytes / (1024**2):.2f} MB")
    print(f"  å†å²é•¿åº¦      = {s + max_gen_len - 1} tokens")



#     # === Visualization ===
#     grouped = df.groupby('Phase')[['FLOPs', 'Total Bytes']].sum()
#     grouped['FLOPs'] /= 1e9  # Convert to GFLOPs
#     grouped['Total Bytes'] /= 1024 ** 2  # Convert to MB

#     ax = grouped.plot(kind='bar', secondary_y='Total Bytes', figsize=(10, 5))
#     ax.set_ylabel("FLOPs (G)")
#     ax.right_ax.set_ylabel("Memory Access (MB)")
#     ax.set_title(f"Phase-wise Computation vs Memory ({L} Layers)")
#     plt.tight_layout()
#     plt.savefig("phasewise_flops_memory.png")
#     plt.show()

#    # df.to_csv(output_csv_path, index=False)
#     print(f"\nâœ… CSV saved to '{output_csv_path}', chart saved to 'phasewise_flops_memory.png'")
    
# # è¿è¡Œåˆ†æï¼Œæ·»åŠ intermediate_sizeå‚æ•°å’Œnum_key_value_headså‚æ•°
# # æ ¹æ®BitNeté…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨æ­£ç¡®çš„å‚æ•°
# compute_and_plot_transformer_analysis(
#     hidden_size=2560,
#     num_heads=20,
#     seq_len=4096,
#     batch_size=1,
#     num_layers=30,
#     intermediate_size=6912,  # ä»BitNeté…ç½®æ–‡ä»¶ä¸­è·å–
#     num_key_value_heads=5,   # ä»BitNeté…ç½®æ–‡ä»¶ä¸­è·å–
#     out_l = 0,
#     max_gen_len = 4096,      # æœ€å¤§ç”Ÿæˆé•¿åº¦
#     quant_config={
#         "activation": 8,
#         "kv_cache": 4,
#         "weight_ffn": 2,
#         "weight_attn": 2
#     },
#     use_gate_ffn=True,  # å¯ç”¨gateæœºåˆ¶
#     use_rope=True,      # å¯ç”¨RoPE
#     rope_theta=10000.0, # æ ‡å‡†RoPE thetaå‚æ•°
#     rope_scaling_factor=1.0, # ä¸è¿›è¡Œç¼©æ”¾
#     output_csv_path="true_density_transformer_analysis.csv"
# )

    # æ·»åŠ RoPEç›¸å…³çš„åˆ†æ
    if use_rope:
        print(f"\nğŸ”„ RoPEåˆ†æ:")
        print(f"  åŸºç¡€theta: {rope_theta}")
        print(f"  ç¼©æ”¾å› å­: {rope_scaling_factor}")
        print(f"  æœ€å¤§ä½ç½®: {s + max_gen_len - 1}")
        
        # è®¡ç®—æœ€å¤§é¢‘ç‡
        max_freq = 1.0 / (rope_theta * rope_scaling_factor)
        nyquist_freq = 0.5  # å¥ˆå¥æ–¯ç‰¹é¢‘ç‡
        
        # è®¡ç®—RoPEçš„æœ‰æ•ˆä¸Šä¸‹æ–‡é•¿åº¦
        effective_context_length = int(np.pi / (max_freq * np.pi / (d // 2)))
        
        print(f"  æœ€å¤§é¢‘ç‡: {max_freq:.6f}")
        print(f"  ç†è®ºæœ‰æ•ˆä¸Šä¸‹æ–‡é•¿åº¦: ~{effective_context_length}")
        
        if s + max_gen_len > effective_context_length:
            print(f"  âš ï¸ è­¦å‘Š: å½“å‰åºåˆ—é•¿åº¦({s + max_gen_len})è¶…è¿‡äº†ç†è®ºæœ‰æ•ˆä¸Šä¸‹æ–‡é•¿åº¦({effective_context_length})ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™")
        else:
            print(f"  âœ… å½“å‰åºåˆ—é•¿åº¦({s + max_gen_len})åœ¨ç†è®ºæœ‰æ•ˆä¸Šä¸‹æ–‡é•¿åº¦({effective_context_length})èŒƒå›´å†…")

    # === Visualization ===
    grouped = df.groupby('Phase')[['FLOPs', 'Total Bytes']].sum()
    grouped['FLOPs'] /= 1e9  # Convert to GFLOPs
    grouped['Total Bytes'] /= 1024 ** 2  # Convert to MB

    ax = grouped.plot(kind='bar', secondary_y='Total Bytes', figsize=(10, 5))
    ax.set_ylabel("FLOPs (G)")
    ax.right_ax.set_ylabel("Memory Access (MB)")
    ax.set_title(f"Phase-wise Computation vs Memory ({L} Layers)")
    plt.tight_layout()
    plt.savefig("phasewise_flops_memory.png")
    plt.show()

   # df.to_csv(output_csv_path, index=False)
    print(f"\nâœ… CSV saved to '{output_csv_path}', chart saved to 'phasewise_flops_memory.png'")
    
# è¿è¡Œåˆ†æï¼Œæ·»åŠ intermediate_sizeå‚æ•°å’Œnum_key_value_headså‚æ•°
# æ ¹æ®BitNeté…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨æ­£ç¡®çš„å‚æ•°
# compute_and_plot_transformer_analysis(
#     hidden_size=2560,
#     num_heads=20,
#     seq_len=4096,
#     batch_size=1,
#     num_layers=30,
#     intermediate_size=6912,  # ä»BitNeté…ç½®æ–‡ä»¶ä¸­è·å–
#     num_key_value_heads=5,   # ä»BitNeté…ç½®æ–‡ä»¶ä¸­è·å–
#     out_l = 0,
#     max_gen_len = 4096,      # æœ€å¤§ç”Ÿæˆé•¿åº¦
#     quant_config={
#         "activation": 8,
#         "kv_cache": 4,
#         "weight_ffn": 2,
#         "weight_attn": 2,
#         "rope_bit": 16
#     },
#     use_gate_ffn=True,  # å¯ç”¨gateæœºåˆ¶
#     use_rope=True,      # å¯ç”¨RoPE
#     rope_theta=500000.0, # æ ‡å‡†RoPE thetaå‚æ•°
#     rope_scaling_factor=1.0, # ä¸è¿›è¡Œç¼©æ”¾
#     output_csv_path="true_density_transformer_analysis.csv"
# )
# compute_and_plot_transformer_analysis(
#         #llama3-8B BF16
#     hidden_size=4096,
#     num_heads=32,
#     seq_len=4096,
#     batch_size=1,
#     num_layers=32,
#     intermediate_size=14336,  # ä»BitNeté…ç½®æ–‡ä»¶ä¸­è·å–
#     num_key_value_heads=8,   # ä»BitNeté…ç½®æ–‡ä»¶ä¸­è·å–
#     out_l = 0,
#     max_gen_len = 4096,      # æœ€å¤§ç”Ÿæˆé•¿åº¦
#     quant_config={
#         "activation": 16,
#         "kv_cache": 16,
#         "weight_ffn": 16,
#         "weight_attn": 16,
#         "rope_bit": 16
#     },
#     use_gate_ffn=True,  # å¯ç”¨gateæœºåˆ¶
#     use_rope=True,      # å¯ç”¨RoPE
#     rope_theta=500000.0, # æ ‡å‡†RoPE thetaå‚æ•°
#     rope_scaling_factor=1.0, # ä¸è¿›è¡Œç¼©æ”¾
#     output_csv_path="llama-true_density_transformer_analysis.csv"
# )

compute_and_plot_transformer_analysis(
        #llama-65B FP16
    hidden_size=8192,
    num_heads=64,
    seq_len=4096,
    batch_size=1,
    num_layers=80,
    intermediate_size=22016,  # ä»BitNeté…ç½®æ–‡ä»¶ä¸­è·å–
    num_key_value_heads=64,   # ä»BitNeté…ç½®æ–‡ä»¶ä¸­è·å–
    out_l = 0,
    max_gen_len = 4096,      # æœ€å¤§ç”Ÿæˆé•¿åº¦
    quant_config={
        "activation": 16,
        "kv_cache": 16,
        "weight_ffn": 16,
        "weight_attn": 16,
        "rope_bit": 16
    },
    use_gate_ffn=True,  # å¯ç”¨gateæœºåˆ¶
    use_rope=True,      # å¯ç”¨RoPE
    rope_theta=500000.0, # æ ‡å‡†RoPE thetaå‚æ•°
    rope_scaling_factor=1.0, # ä¸è¿›è¡Œç¼©æ”¾
    output_csv_path="llama65B-true_density_transformer_analysis.csv"
)



